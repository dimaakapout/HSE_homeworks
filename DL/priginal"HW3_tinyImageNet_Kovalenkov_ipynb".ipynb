{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "priginal\"HW3_tinyImageNet_Kovalenkov.ipynb\"",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dimaakapout/HSE_homeworks/blob/master/DL/priginal%22HW3_tinyImageNet_Kovalenkov_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB_Ax7xfLDDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plt.imshow(x1[0].cpu().numpy().transpose(1,2,0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIB8HWa4LDBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ОТЧЕТ \n",
        "\n",
        "1. арх 2конв + свертка + линейный 600-200 дали около 20%"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ITenLraoq93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_step(batch, model, device=torch.device('cpu')):\n",
        "    data, target = batch\n",
        "    \n",
        "    # закидываем данные и модель на один и тот же device\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    model.to(device)\n",
        "    \n",
        "    # включаем train mode (обязательно например при наличии dropout, batch_norm и т.д.)\n",
        "    model.train()\n",
        "    \n",
        "    logits = model(data)\n",
        "    loss = F.cross_entropy(logits, target)\n",
        "    \n",
        "    # loss.item() эквивалентно loss.detach().cpu().numpy()\n",
        "    logs = {'train_ce_loss': loss.item()}\n",
        "    \n",
        "    return {'loss': loss, 'log': logs}\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, scheduler=None, device=torch.device('cpu')):\n",
        "    logs = []\n",
        "    for batch in tqdm(loader):\n",
        "        output = training_step(batch, model, device)\n",
        "        loss = output['loss']\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        logs.append(output['log'])\n",
        "    return logs\n",
        "\n",
        "def train_epoch_end(logs):\n",
        "    avg_train_ce_loss = np.mean([x['train_ce_loss'] for x in logs])\n",
        "    return {'avg_train_ce_loss': avg_train_ce_loss}\n",
        "\n",
        "def validation_step(batch, model, device=torch.device('cpu')):\n",
        "    data, target = batch\n",
        "    \n",
        "    # закидываем данные и модель на один и тот же device\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    model.to(device)\n",
        "    \n",
        "    # включаем eval mode (обязательно например при наличии dropout, batch_norm и т.д.)\n",
        "    model.eval()\n",
        "    \n",
        "    start_time = time.perf_counter()\n",
        "    with torch.no_grad():\n",
        "        logits = model(data)\n",
        "    inference_time_per_batch = time.perf_counter() - start_time\n",
        "    \n",
        "    pred = logits.argmax(dim=1, keepdim=True)\n",
        "    \n",
        "    correct = pred.eq(target.view_as(pred)).sum().item()\n",
        "    log = {'correct': correct, 'inference_time_per_batch': inference_time_per_batch, 'amount': pred.shape[0]}\n",
        "    return {'log': log}\n",
        "\n",
        "def val_one_epoch(model, loader, device=torch.device('cpu')):\n",
        "    logs = []\n",
        "    for batch in tqdm(loader):\n",
        "        output = validation_step(batch, model, device)\n",
        "        logs.append(output['log'])\n",
        "    return logs\n",
        "        \n",
        "def validation_epoch_end(logs):\n",
        "    total_amount = np.sum([x['amount'] for x in logs])\n",
        "    total_correct = np.sum([x['correct'] for x in logs])\n",
        "    accuracy = 100 * total_correct / total_amount \n",
        "    avg_inference_time_per_batch = np.mean([x['inference_time_per_batch'] for x in logs])\n",
        "    return {'val_accuracy (%)': accuracy, 'avg_inference_time_per_batch (sec)': avg_inference_time_per_batch}\n",
        "    \n",
        "def configure_optimizers(model):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
        "    scheduler = None\n",
        "    return optimizer, scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gNAD9E2k0Pz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "optimizer, scheduler = configure_optimizers(model)\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch}:\")\n",
        "    train_logs = train_one_epoch(model, train_loader, optimizer, scheduler, device)\n",
        "    print(train_epoch_end(train_logs))\n",
        "    val_logs = val_one_epoch(model, val_loader, device)\n",
        "    print(validation_epoch_end(val_logs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOXfxSCDk0NN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Test stage:\")\n",
        "val_logs = val_one_epoch(model, val_loader)\n",
        "print(validation_epoch_end(val_logs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkEuWkWWbLGf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "outputId": "df888d31-e7c6-4ddc-ec0d-c6f8410f668a"
      },
      "source": [
        "val_accuracy = comput_val_acc(...)\n",
        "print(\"Validation accuracy: %.2f%%\" % (val_accuracy * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-268882aeb904>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomput_val_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation accuracy: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval_accuracy\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'comput_val_acc' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCc1xvdQSS28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhN5SCPhF1_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A-47IArAYsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Параметры модели\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "9pbjYIlybLFx",
        "colab_type": "text"
      },
      "source": [
        "# Homework 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gtGRfyMbLF2",
        "colab_type": "text"
      },
      "source": [
        "Домашние задания являются полностью опциональными, оценки никуда не идут.\n",
        "\n",
        "### Дедлайн: 21.06.20 (вс) 21:00 мск\n",
        "\n",
        "### Формат сдачи\n",
        "\n",
        "__Вариант 1__: этот ipynb файл с кодом\n",
        "\n",
        "дополнительно добавьте:\n",
        "* \"checkpoint\" файл из `torch.save(model.state_dict(), ...)` который содержит веса модели для задачи 1, 3 и поможет удостовериться в точности на валидации\n",
        "* имеется возможность перезапустить весь ipynb файл, чтобы убедиться в финальном результате, например в 1й и 3й задаче (можете сделать конструкцию if else, н: если файл с весами присутствует, тогда показываем точность, иначе запускаем training рутину и выводим в конце точность)\n",
        "\n",
        "__Вариант 2__:\n",
        "сдаёте в виде набора .py скриптов (н. train.py, test.py, ...) на каждое задание с инструкцией как запустить и убедиться в полученных вами результатах"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac_iHQymbLF5",
        "colab_type": "text"
      },
      "source": [
        "# Задача 1 - Train your own model (6 баллов)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3gFVudKbLF9",
        "colab_type": "text"
      },
      "source": [
        "В этом задании вы построете сверточную нейросеть (CNN) для решения Tiny ImageNet классификации. Постарайтесь добиться максимальной точности на валидации.\n",
        "\n",
        "### Оценивание\n",
        "\n",
        "* За преодоление каждого порога даётся 1 балл\n",
        "  * 25.0%\n",
        "  * 30.0%\n",
        "  * 32.5%\n",
        "  * 35.0%\n",
        "  * 37.5%\n",
        "  * 40.0%\n",
        "    \n",
        "### Ограничения\n",
        "\n",
        "* __Нельзя использовать предобученные нейросети.__ Сами архитектуры использовать можно.\n",
        "\n",
        "### Советы\n",
        "\n",
        "* Одно изменение в один момент времени\n",
        "* Используйте GPU, постарайтесь написать device-agnostic код, чтобы нигде не присутствовало `.cuda()`, а было `.to(device)`\n",
        "* Логируйте промежуточный результаты, например в TensorBoard\n",
        "* С чем можно поиграться: optimizer, lr scheduler, архитектура, инициализации, loss, регуляризации (dropout, cutmix, weight decay, аугментации и тд), и кучу всего разного\n",
        "* Про \"фишечки\", которые можно внедрить для улучшения качества, можно посмотреть здесь https://arxiv.org/abs/1812.01187\n",
        "* Постарайтесь по максимуму переиспользовать написанный код, то есть реализовать в виде набора функций например тренировочную рутину и ее использовать в задаче 1, 2, 4\n",
        "* Как обычно: читабельный, понятный код приветствуется\n",
        "\n",
        "### Какую архитектуру выбрать для обучения?\n",
        "* пишем сами\n",
        "* берём готовую архитектуру (например отсюда https://github.com/rwightman/pytorch-image-models (очень классный ресурс с модными архитектурами) или отсюда https://pytorch.org/docs/stable/torchvision/models.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf-UJL4rbLGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoC1CuUkSxvj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (15.0, 12.0) # размер изображений по умолчанию"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eGjsqCobLGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import tiny_imagenet\n",
        "#tiny_imagenet.download(\".\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8jJl25ULWsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip # Stanford 200 imagenet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDm63-G4bLGV",
        "colab_type": "text"
      },
      "source": [
        "Тренировочные и валидационные данные лежат в `tiny-imagenet-200/train` и `tiny-imagenet-200/val`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6Nb7JcLLtEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from urllib.request import urlretrieve\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnxiSQLNOjeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Разархивация архива\n",
        "if not os.path.exists(\"tiny-imagenet-200\"):\n",
        "    import zipfile\n",
        "    with zipfile.ZipFile(\"tiny-imagenet-200.zip\", 'r') as archive:\n",
        "        archive.extractall(\"tiny-imagenet-200\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRs2btvefmIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Разархивация архива\n",
        "if not os.path.exists(\"tiny-imagenet-200\"):\n",
        "    import zipfile\n",
        "    with zipfile.ZipFile(\"tiny-imagenet-200.zip\", 'r') as archive:\n",
        "        archive.extractall(\"tiny-imagenet-200\")\n",
        "\n",
        "\n",
        "dataset_root = \"tiny-imagenet-200/tiny-imagenet-200\"\n",
        "\n",
        "train_dataset = torchvision.datasets.ImageFolder(\n",
        "    os.path.join(dataset_root, \"train\"),\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2768, 0.2689, 0.2819])\n",
        "    ]))\n",
        "test_dataset = torchvision.datasets.ImageFolder(\n",
        "    os.path.join(dataset_root, \"test\"),\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2768, 0.2689, 0.2819])\n",
        "    ]))\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "loaderGGGTrain = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True, \n",
        "    drop_last=True,\n",
        "    num_workers=1)\n",
        "\n",
        "iterator = iter(loaderGGGTrain)\n",
        "X, Y = iterator.next()\n",
        "\n",
        "loaderGGGTest = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True, \n",
        "    drop_last=True,\n",
        "    num_workers=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wW2LxMbPt9QT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c09f888d-6a85-4eb5-a84a-33314538f7f5"
      },
      "source": [
        "batch_size = 500\n",
        "\n",
        "total_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False, # False чтобы не перемешать классы\n",
        "    drop_last=True,\n",
        "    num_workers=1)\n",
        "\n",
        "total_iter = iter(total_loader)\n",
        "\n",
        "# В цикле переберем все классы и создадим массив по 100 примеров каждого класса\n",
        "for i in tqdm(range(10)): # Первые 10 классов\n",
        "  n_images = 200\n",
        "  images, labels = total_iter.next()\n",
        "  x = images.numpy()\n",
        "  y = labels.numpy()\n",
        "  if i == 0:\n",
        "    dataTrainX = x[:n_images]\n",
        "    dataTrainY = y[:n_images]\n",
        "    dataTestX = x[n_images:n_images+100]\n",
        "    dataTestY = y[n_images:n_images+100]             \n",
        "    continue\n",
        "  dataTrainX = np.vstack((dataTrainX, x[:n_images]))\n",
        "  dataTrainY = np.hstack((dataTrainY, y[:n_images]))\n",
        "  dataTestX = np.vstack((dataTestX, x[n_images:n_images+100]))\n",
        "  dataTestY = np.hstack((dataTestY, y[n_images:n_images+100]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  4.21it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HMqq9wAfmBI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6ede51b2-8fb2-470b-c308-eb8897cd9d76"
      },
      "source": [
        "dataTestX.shape, dataTrainX.shape, dataTrainY.shape, dataTestY.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000, 3, 64, 64), (2000, 3, 64, 64), (2000,), (1000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdvYHIMtgoYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Свой датасет\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, xdata, ydata):\n",
        "\n",
        "        self.target = ydata\n",
        "        self.images = xdata\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.target)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "\n",
        "        image = self.images[idx]\n",
        "        target = self.target[idx]\n",
        "        sample = [image, target]\n",
        "        \n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH0FaXfsgoWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainData = CustomDataset(dataTrainX, dataTrainY)\n",
        "testData = CustomDataset(dataTestX, dataTestY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK_kRX67kcIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 50\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    trainData,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=1)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    testData,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=1)\n",
        "\n",
        "train_iter = iter(train_loader)\n",
        "test_iter = iter(test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDFvXyo0kcF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train = train_iter.next()\n",
        "x_test, y_test = test_iter.next()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ28Bf3o1XOS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "6b550885-7a58-41fa-d09b-eccc49068d19"
      },
      "source": [
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([50, 3, 64, 64]),\n",
              " torch.Size([50, 3, 64, 64]),\n",
              " torch.Size([50]),\n",
              " torch.Size([50]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7e0F_4NbLGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset_root = \"tiny-imagenet-200/tiny-imagenet-200\"\n",
        "\n",
        "# train_dataset = torchvision.datasets.ImageFolder(\n",
        "#     os.path.join(dataset_root, \"train\"),\n",
        "#     transform=transforms.Compose([\n",
        "#         transforms.ToTensor(),\n",
        "#         transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2768, 0.2689, 0.2819])\n",
        "#     ]))\n",
        "\n",
        "# val_dataset = torchvision.datasets.ImageFolder(\n",
        "#     os.path.join(dataset_root, \"val\"),\n",
        "#     transform=transforms.Compose([\n",
        "#         transforms.ToTensor(),\n",
        "#         transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2768, 0.2689, 0.2819])\n",
        "#     ]))\n",
        "\n",
        "# batch_size = 30\n",
        "# train_loader = torch.utils.data.DataLoader(\n",
        "#     train_dataset,\n",
        "#     batch_size=batch_size,\n",
        "#     shuffle=True,\n",
        "#     drop_last=True,\n",
        "#     num_workers=1)\n",
        "# val_loader = torch.utils.data.DataLoader(\n",
        "#     val_dataset,\n",
        "#     batch_size=batch_size,\n",
        "#     shuffle=False,\n",
        "#     num_workers=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZjvHVbvPxBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_iter = iter(train_loader)\n",
        "# images, labels = train_iter.next()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRFMckm2TYne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.imshow(images[0].numpy().transpose(1,2,0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERY54paDST2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make grid takes tensor as arg\n",
        "# tensor : (batchsize, channels, height, width)\n",
        "# grid = torchvision.utils.make_grid(images, pad_value=2)\n",
        "\n",
        "# plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
        "# plt.axis('off')\n",
        "# plt.title(labels.numpy());"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKSY5N-o_XWc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "55a42aea-8d86-4f48-bae7-cc4131018834"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7UrVYvr_cga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-CTfyuJ1VUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, (3,3), stride=2)\n",
        "    self.conv2 = nn.Conv2d(6, 12, (3,3), stride=1)\n",
        "    self.maxpool1 = nn.MaxPool2d((3,3))\n",
        "\n",
        "    self.conv3 = nn.Conv2d(12, 24, (3,3), stride=1)\n",
        "    self.conv4 = nn.Conv2d(24, 48, (3,3), stride=1)\n",
        "    self.conv5 = nn.Conv2d(48, 96, (3,3), stride=1)\n",
        "\n",
        "    self.fc1 = nn.Linear(864, 200) # НЕ ЗАБЫВАТЬ МЕНЯТЬ ЧИСЛО КЛАССОВ\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.maxpool1(x)\n",
        "\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = F.relu(self.conv4(x))\n",
        "    x = F.relu(self.conv5(x))\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.fc1(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XyOvojKn0QF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model2, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, (3,3), stride=2)\n",
        "    self.bn1 = nn.BatchNorm2d(6)\n",
        "    self.conv2 = nn.Conv2d(6, 12, (3,3), stride=1)\n",
        "    self.bn2 = nn.BatchNorm2d(12)\n",
        "    self.maxpool1 = nn.MaxPool2d((3,3))\n",
        "\n",
        "    self.conv3 = nn.Conv2d(12, 24, (3,3), stride=1)\n",
        "    self.bn3 = nn.BatchNorm2d(24)\n",
        "    self.conv4 = nn.Conv2d(24, 48, (3,3), stride=1)\n",
        "    self.bn4 = nn.BatchNorm2d(48)\n",
        "    self.conv5 = nn.Conv2d(48, 96, (3,3), stride=1)\n",
        "    self.bn5 = nn.BatchNorm2d(96)\n",
        "    self.fc1 = nn.Linear(864, 200) \n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.bn1(self.conv1(x))\n",
        "    x = F.relu(x)\n",
        "    x = self.bn2(self.conv2(x))\n",
        "    x = F.relu(x)    \n",
        "    x = self.maxpool1(x)\n",
        "\n",
        "    x = self.bn3(self.conv3(x))\n",
        "    x = F.relu(x)    \n",
        "    x = self.bn4(self.conv4(x))\n",
        "    x = F.relu(x)\n",
        "    x = self.bn5(self.conv5(x))\n",
        "    x = F.relu(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.fc1(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORzacxzm8y9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = Model()\n",
        "# model.forward(x_train).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmWrMFKhkUJt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0d8bfde0-1dc9-49b8-f017-b1217b1a3cf1"
      },
      "source": [
        "model = Model2()\n",
        "model(X).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 200])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z070w1Mz7eKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model()\n",
        "criterion = F.cross_entropy\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1PNhUnbBRuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Обучение и валидация\n",
        "\n",
        "def training_step(batch, model, device=torch.device('cpu')):\n",
        "  data, target = batch\n",
        "  data = data.to(device)\n",
        "  target = target.to(device)\n",
        "  model.to(device)\n",
        "\n",
        "  model.train(mode=True)\n",
        "\n",
        "  output = model(data)\n",
        "  loss = F.cross_entropy(output, target)\n",
        "\n",
        "  return loss\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device=torch.device('cpu')):\n",
        "  logs = np.array([])\n",
        "  for batch in tqdm(loader):\n",
        "    loss_batch = training_step(batch, model, device)\n",
        "    optimizer.zero_grad()\n",
        "    loss_batch.backward()\n",
        "    optimizer.step()\n",
        "    logs = np.append(logs, loss_batch.item())\n",
        "    \n",
        "  return logs.mean()\n",
        "\n",
        "def validation_step(batch, model, device=torch.device('cpu')):\n",
        "    \n",
        "    # закидываем данные и модель на один и тот же device\n",
        "    data, target = batch\n",
        "    data = data.to(device)\n",
        "    target = target.to(device)\n",
        "    model.to(device)\n",
        "    \n",
        "    # включаем eval mode (обязательно например при наличии dropout, batch_norm и т.д.)\n",
        "    model.train(mode=False)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      output = model(data)\n",
        "    #output = model(data)\n",
        "    loss = F.cross_entropy(output, target)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def val_one_epoch(model, loader, device=torch.device('cpu')):\n",
        "    logs = np.array([])\n",
        "    for batch in tqdm(loader):\n",
        "        val_loss = validation_step(batch, model, device)\n",
        "        logs = np.append(logs, val_loss.item())\n",
        "    return logs.mean()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNfbWl__G2Lq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# top N accuracy\n",
        "\n",
        "def topN_epoch(model, loader, device, n):\n",
        "    logs = np.array([])\n",
        "    for batch in tqdm(loader):\n",
        "        acc = topN_step(batch, model, device, n)\n",
        "        logs = np.append(logs, acc)\n",
        "    return logs.mean()\n",
        "\n",
        "def topN_step(batch, model, device, n):\n",
        "    \n",
        "    data, target = batch\n",
        "    data = data.to(device)\n",
        "    target = target.to(device)\n",
        "    model.to(device)\n",
        "    \n",
        "    model.train(mode=False)\n",
        "    \n",
        "    output = model(data)\n",
        "    acc = compute_acc(output, target, n)\n",
        "\n",
        "    return acc\n",
        "\n",
        "def compute_acc(output, target, N):\n",
        "  predict = np.array([])\n",
        "\n",
        "  for ii in output:\n",
        "      ans = np.array([])\n",
        "      ii =  ii.cpu().detach().numpy()\n",
        "      for n in range(N):\n",
        "        idx = ii.argmax()\n",
        "        np.put(ii,idx, -1000)\n",
        "        ans = np.append(ans, idx)\n",
        "      predict = np.append(predict, ans)\n",
        "  predict = np.array(np.split(predict, output.shape[0]))\n",
        "  accuracy = np.array([])\n",
        "  for y,x in zip(target, predict):\n",
        "    if y.item() in x:\n",
        "      accuracy = np.append(accuracy, 1)\n",
        "    else:\n",
        "      accuracy = np.append(accuracy, 0)\n",
        "  return accuracy.mean()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3ssGDZoEu_f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "168c2c8e-c663-42d9-c7ee-cb7f24a56e93"
      },
      "source": [
        "doc = np.array([])\n",
        "docval = np.array([])\n",
        "early_stopping_rate = 1000\n",
        "count = 0\n",
        "for i in range(30):\n",
        "  docs = train_one_epoch(model, loaderGGGTrain, optimizer, device) # loader\n",
        "  docs_ = val_one_epoch(model, loaderGGGTest, device)\n",
        "  doc = np.append(doc, docs)\n",
        "  docval = np.append(docval, docs_)\n",
        "  print(\"\\n\\tEpoch #%s\" %i)\n",
        "  print(\"\\ttrain_loss =%.3f\" %doc[-1], \"val_loss =%.3f\" %docval[-1], '\\n')\n",
        "  \n",
        "  # Ранняя остановка\n",
        "  if docval[-1] < early_stopping_rate:\n",
        "    early_stopping_rate = docval[-1]\n",
        "    count = 0\n",
        "  else:\n",
        "    count += 1\n",
        "    if count == 3:\n",
        "      break\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1562/1562 [00:51<00:00, 30.57it/s]\n",
            "100%|██████████| 156/156 [00:04<00:00, 31.34it/s]\n",
            "  0%|          | 0/1562 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tEpoch #0\n",
            "\ttrain_loss =3.764 val_loss =8.641 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1562/1562 [00:51<00:00, 30.08it/s]\n",
            "100%|██████████| 156/156 [00:05<00:00, 31.11it/s]\n",
            "  0%|          | 0/1562 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tEpoch #1\n",
            "\ttrain_loss =3.743 val_loss =9.471 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1562/1562 [00:52<00:00, 29.84it/s]\n",
            "100%|██████████| 156/156 [00:05<00:00, 31.13it/s]\n",
            "  0%|          | 0/1562 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tEpoch #2\n",
            "\ttrain_loss =3.723 val_loss =9.925 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1562/1562 [00:52<00:00, 29.87it/s]\n",
            "100%|██████████| 156/156 [00:05<00:00, 30.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tEpoch #3\n",
            "\ttrain_loss =3.704 val_loss =9.538 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnChofEtp0tq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " TOP1 accuracy = 0.252\n",
        "100%|██████████| 20/20 [00:00<00:00, 74.11it/s]\n",
        " TOP5 accuracy = 0.497\n",
        "\n",
        "  TOP1 accuracy = 0.290\n",
        "100%|██████████| 20/20 [00:00<00:00, 73.24it/s]\n",
        " TOP5 accuracy = 0.526"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Kbr5SH0fPwS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "dea410bc-9a0f-4ae3-d0c0-430d6128592f"
      },
      "source": [
        "print('\\n', 'TOP1 accuracy = %.3f' % topN_epoch(model, test_loader, device, n=1))\n",
        "print('\\n', 'TOP5 accuracy = %.3f' % topN_epoch(model, test_loader, device, n=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 80.31it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " TOP1 accuracy = 0.241\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 67.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " TOP5 accuracy = 0.460\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUULkO_ErrTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#torch.save(model.state_dict(), r'./model.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_eadHxqs83q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "outputId": "63b3789d-65f5-4d77-81a1-6ee59352ef44"
      },
      "source": [
        "# Learning curve\n",
        "plt.plot(doc, '*-', label='train')\n",
        "plt.plot(docval, label='val')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f16860c8550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOMDs6vVLDGy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2ee0da6a-0eee-48d7-b0f3-3833fb8e47cb"
      },
      "source": [
        "# ЧИСЛО ПАРАМЕТРОВ МОДЕЛИ \n",
        "sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "228428"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYvwbfs1bLGk",
        "colab_type": "text"
      },
      "source": [
        "### Отчет\n",
        "\n",
        "Кратако укажите, что вы попробывали, что получилось и дало прирост, а что нет\n",
        "\n",
        "Сколько параметров у модели?\n",
        "\n",
        "Как быстро она предсказывает класс для 1й картинки?\n",
        "\n",
        "Oпцианально: выведите top-1, top-5 точность вашей модели\n",
        "\n",
        "Опцианально: выведите картинки, на которых ваша модель сильнее всего ошибается (вероятность класса, соответствующая таргету, минимальная)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfTeSmz8FjAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "модель 1\n",
        "TOP1 accuracy = 0.252\n",
        "TOP5 accuracy = 0.497\n",
        "\n",
        "модель 2\n",
        "TOP1 accuracy = 0.290\n",
        "TOP5 accuracy = 0.526"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIkdV4tGbLGe",
        "colab_type": "text"
      },
      "source": [
        "Когда закончите обучение, сделайте отдельно инференс на валидации и выведите ниже результат."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu8N3sGcAYz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ogVmpLYAY22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvGnJ_j9AY5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTuJiiYFAY9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx9oML68bLGl",
        "colab_type": "text"
      },
      "source": [
        "# Задача 2 - Transfer Learning (1 балл)\n",
        "\n",
        "Выберите любую предобученную модель. Сделайте transfer learning для датасета из задачи 1. Постарайтесь по-максимуму воспользоваться кодом из задачи 1, чтобы не дублировать его. Выведите точность на валидации."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1244jaC5bLGm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "c34aa549-5788-44b6-bf0b-d7bea8f65d9e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on package torchvision.models in torchvision:\n",
            "\n",
            "NAME\n",
            "    torchvision.models\n",
            "\n",
            "PACKAGE CONTENTS\n",
            "    _utils\n",
            "    alexnet\n",
            "    densenet\n",
            "    detection (package)\n",
            "    googlenet\n",
            "    inception\n",
            "    mnasnet\n",
            "    mobilenet\n",
            "    quantization (package)\n",
            "    resnet\n",
            "    segmentation (package)\n",
            "    shufflenetv2\n",
            "    squeezenet\n",
            "    utils\n",
            "    vgg\n",
            "    video (package)\n",
            "\n",
            "FILE\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/__init__.py\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz0Jg3ZyzOu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet50 = torchvision.models.resnet50(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNAH5bW1zdYP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2aaf8c2c-cfbb-41e9-c276-e6818bc2b1d8"
      },
      "source": [
        "resnet50"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQi0ryyLzdVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ПИШЕМ ЦИКЛ ОБУЧЕНИЯ\n",
        "criterion = F.cross_entropy\n",
        "optimizer = torch.optim.Adam(resnet50.parameters())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogrhJEYs1Vrj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "e424b8c3-d07b-430c-d7f6-1093fde1151a"
      },
      "source": [
        "doc = np.array([])\n",
        "docval = np.array([])\n",
        "early_stopping_rate = 1000\n",
        "count = 0\n",
        "for i in range(3):\n",
        "  docs = train_one_epoch(resnet50, loaderGGGTrain, optimizer, device) # loader\n",
        "  docs_ = val_one_epoch(resnet50, loaderGGGTest, device)\n",
        "  doc = np.append(doc, docs)\n",
        "  docval = np.append(docval, docs_)\n",
        "  print(\"\\n\\tEpoch #%s\" %i)\n",
        "  print(\"\\ttrain_loss =%.3f\" %doc[-1], \"val_loss =%.3f\" %docval[-1], '\\n')\n",
        "  \n",
        "  # Ранняя остановка\n",
        "  if docval[-1] < early_stopping_rate:\n",
        "    early_stopping_rate = docval[-1]\n",
        "    count = 0\n",
        "  else:\n",
        "    count += 1\n",
        "    if count == 3:\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1562/1562 [00:57<00:00, 27.08it/s]\n",
            "100%|██████████| 156/156 [00:05<00:00, 26.69it/s]\n",
            "  0%|          | 0/1562 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tEpoch #0\n",
            "\ttrain_loss =3.196 val_loss =13.236 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1562/1562 [00:58<00:00, 26.86it/s]\n",
            "100%|██████████| 156/156 [00:05<00:00, 26.77it/s]\n",
            "  0%|          | 0/1562 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tEpoch #1\n",
            "\ttrain_loss =2.768 val_loss =13.751 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1562/1562 [00:57<00:00, 26.98it/s]\n",
            "100%|██████████| 156/156 [00:05<00:00, 26.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tEpoch #2\n",
            "\ttrain_loss =2.617 val_loss =12.070 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_y-MOC7bLGr",
        "colab_type": "text"
      },
      "source": [
        "# Задача 3 - Grouped Convolutions (2 балла)\n",
        "\n",
        "Задача на понимание групповых сверток.\n",
        "\n",
        "Стандартный вариант указать параметр __groups__  у `nn.Conv2d` и вызвать стандартный forward.\n",
        "\n",
        "Попробуйте написать `forward` сами, воспользовавшись `torch.nn.functional.conv2d()` с одним ограничением, что параметр __groups__ в `torch.nn.functional.conv2d()` передавать нельзя.\n",
        "\n",
        "Для решения советую циклом пройтись по `range(out_channels)` возможно с ненулевым шагом."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEgeYE3XbLGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def custom_forward(conv, x):\n",
        "    # put your code here\n",
        "    return result\n",
        "\n",
        "conv = nn.Conv2d(in_channels=8, out_channels=32, kernel_size=3, groups=2, padding=1)\n",
        "x = torch.rand(1, 8, 16, 16)\n",
        "assert torch.allclose(conv(x), custom_forward(conv, x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdzATMAmbLGw",
        "colab_type": "text"
      },
      "source": [
        "# Задача 4 - Self-supervised learning (много баллов)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4B1uAXKbLGw",
        "colab_type": "text"
      },
      "source": [
        "Если вы дошли до задачи 4 и у вас еще много сил, энергии и времени, то вот вам настоящий challenge:\n",
        "\n",
        "Прочитайте статью про FixMatch https://arxiv.org/abs/2001.07685\n",
        "\n",
        "Вам предлагается в каком-либо виде воспользоваться предлагаемым в статье новым loss-ом применимо к задаче 1. А именно: в статье предлагается вариант того, как эффективно воспользоваться неразмеченными данными для улучшения качества модели.\n",
        "Если у вас написан хороший код для задачи 1, то не должно вызвать больших трудностей добавить упомянутый подход.\n",
        "Смотреть / использовать готовые какие-то реализации разрешается, главное вы должны понимать код, которым воспользовались.\n",
        "\n",
        "Пара советов:\n",
        "* скорей всего в одной из лекций мы покроем как писать свой вариант кастомный класс для загрузки данных, но вы можете сейчас попробовать погуглить (pytorch custom dataset) - он вам скорей всего понадобится, чтобы грузить одновременно размеченные и неразмеченные данные в 1 батче\n",
        "* неразмеченные данные можно взять из любого другого датасета, например cifar-100 либо же для начала можно просто имеющиеся train данные поделить на две части и забыть про существование таргетов на одной из частей\n",
        "* воспользуйтесь той же самой моделью и теми же самыми параметрами оптимизатора и т.д какие вы выбрали в 1й задаче\n",
        "* сильные и слабые аугментации (см. статью) можете сделать внутри вашего кастомного класса с датасетом (т.е. агументировать данные до отправки на gpu) либо делать их уже после загрузки батча из dataloader (желательно на гпу). Во втором варианте советую воспользоваться https://kornia.readthedocs.io/en/latest/augmentation.html\n",
        "* аугментации можете для дз сделать любые свои в качестве слабых и сильных, но на будущее старайтесь реимплемнтировать разные походы из статей как можно более похожим образом для начала, если еще нет интуиции как поменять что-то под вашу задачу, чтобы в случае если вы встраивате метод в какой-то пайплайн и у вас в итоге плохое качество, знать что в этом месте например проблемы нет, значит надо искать в другом месте"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9IoMygzbLGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}